{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronyu888/mat-494-notebooks/blob/main/Elements_of_Linear_Algebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PDqolD8wqc_"
      },
      "source": [
        "# **Chapter 1.2 Elements of Linear Algebra**\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oX6DcS8BzXO"
      },
      "source": [
        "# **1.2.1 Linear Spaces**\n",
        "**Linear Combination**: an expression constructed from a subset by multiplying each term by a constant and adding the results.\n",
        "\n",
        "**Linear Subspace**: a subset U⊆V that is closed under vector addition ($u_1$ + $u_2 \\epsilon U$) and scalar multiplication ($\\alpha u_1 \\epsilon U$)\n",
        "\n",
        "**Span**: the span($w_1$,...,$w_m$) is the set of all linear combinations of $w_j$'s given that $w_1$,...,$w_m \\epsilon V$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zu0drRb71Yw",
        "outputId": "9200a617-0d77-484f-8a2b-d265d67f0f91"
      },
      "source": [
        "a1 = 1\n",
        "a2 = 1\n",
        "u1 = 1\n",
        "u2 = 1\n",
        "x = a1 * u1 + a2 * u2\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBjQjX768WM_"
      },
      "source": [
        "In the code above, $a_1$ and $a_2$ are mutable constants while $u_1$ and $u_2$ are variables. Any combination of values for $a_1$ and $a_2$ will result in *x* being a linear combination. The set of all possible linear combinations of $u_1$ and $u_2$ is the span and is denoted as span($u_1$,$u_2$). span($u_1$,$u_2$) as well as all other spans are linear subspaces because they are comprised of linear combinations, which are inherently closed under vector addition and scalar multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6zTkdA3NC2S"
      },
      "source": [
        "**Linear Independence**: A list of vector $u_1,...,u_m$ is said to be linearly independent if none of them can be written as a linear combination of the others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZKtuM8SNV5a"
      },
      "source": [
        "def dependence_check(vector1, vector2):\n",
        "  matrix = np.stack((vector1, vector2), axis = -1)\n",
        "  det = np.linalg.det(matrix)\n",
        "  if det == 0:\n",
        "    print(\"the vectors are linearly dependent\")\n",
        "  else:\n",
        "    print(\"the vectors are linearly independent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3gMxHiTPRiz",
        "outputId": "efaab9dd-7b89-4a70-b1f2-74e765c22e62"
      },
      "source": [
        "a = np.array([1, 2])\n",
        "b = np.array([2, 4])\n",
        "c = np.array([2, 5])\n",
        "dependence_check(a, b)\n",
        "dependence_check(a, c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the vectors are linearly dependent\n",
            "the vectors are linearly independent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIsYRQYUR12J"
      },
      "source": [
        "The above code checks if the sets of vectors *a* and *b* as well as *a* and *c* are linearly independent. *a* and *b* are not linearly independent because *b* = *a* $\\cdot$ 2. *a* and *c* are linearly independent because neither can be written as a linear combination of another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsxxmNmtSnD1"
      },
      "source": [
        "**Column Space**: the column space of *A*, where *A* is an n x m matrix and *A* ∈ $R^{n \\cdot m}$, is the span of columns of A\n",
        "\n",
        "**Basis**: A basis of *U*, where *U* is a linear subspace of *V*, is a list of vectors $u_1,...,u_m$ that span *U* and are linearly independent. A basis is a unique representation and will always have the same dimension as other bases of *U*.\n",
        "\n",
        "**Dimension**: the number of rows by the number of columns of a matrix.\n",
        "\n",
        "**Rank**: the dimension of the vector space spanned by a matrix's columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTa6SC8kLWd7"
      },
      "source": [
        "import numpy as np\n",
        "import pprint\n",
        "def column_space(matrix):\n",
        "  b = a.transpose()\n",
        "  rank = 0\n",
        "  for row in b:\n",
        "    rank += 1\n",
        "    print(row)\n",
        "  print(f'rank: {rank}')\n",
        "  print(f'dimension: {matrix.size}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OchbHB287vB",
        "outputId": "4b09bf17-db78-4da8-cd8b-e4aa08813375"
      },
      "source": [
        "a = np.array([[1, 2], [3, 4]])\n",
        "column_space(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 3]\n",
            "[2 4]\n",
            "rank: 2\n",
            "dimension: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUDKhlK6J-u5"
      },
      "source": [
        "The column space of *a* would be $\\begin{pmatrix}1\\\\ 3\\end{pmatrix}c_1 + \\begin{pmatrix}2\\\\4\\end{pmatrix}c_2$ for the code above. The basis of the column space would also be {$\\begin{pmatrix}1\\\\3\\end{pmatrix}, \\begin{pmatrix}2\\\\4\\end{pmatrix}$} since these vectors are minimally spanning. The rank is equal to the number of vectors in the column space, while the dimension is equal to the total number of elements in the array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQo5PzDnYGai"
      },
      "source": [
        "# 1.2.2 Orthogonality\n",
        "**Inner Product**: $<u,v> = u \\cdot v = \\sum_i^n u_iv_i$\n",
        "\n",
        "**Norm**: $\\|v\\| = \\sqrt {\\sum_1^n u_i^2}$\n",
        "\n",
        "**Orthonormal**: A list of vectors $u_1,...,u_m$ is orthonormal if the $u_i$'s are pairwise orthogonal and each has norm 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D72mXWo3bOFn",
        "outputId": "2b042473-2b80-467c-8fb8-2b66a52583ac"
      },
      "source": [
        "a = np.identity(3, dtype = int)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf5mq601bZTt"
      },
      "source": [
        "In the code above, the basis of *a* is orthonormal because the $u_i$'s are pairwise orthogonal and each has norm 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7lxqksEcEao"
      },
      "source": [
        "**Best Approximation Theorem**: we have a linear subspace $U \\subseteq V$ and a vector $v \\nsubseteq U$ and we want to find the vector $v^*$ in $U$ that is closest to $v$ in 2-norm. We want to solve $min_{v^* \\epsilon U} \\|v^* - v \\|$. To confirm the optimality of $v^*$, we use the Pythagorean theorem and find that $\\|v - \\alpha u_1 \\|^2 \\geq \\|v - v^* \\|^2$ \n",
        "\n",
        "**Orthogonal Projection**: Let $U \\subseteq V$ be a linear subspace with orthonormal basis $q_1,...,q_m$ and let $v \\epsilon V$. For any $u \\epsilon U$, $\\| v - P_Uv \\| \\leq \\| v - u \\|$. Furthermore, if $u \\epsilon U$ and the previous inequality is an equality, then $u = P_Uv$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXmt3UUuhDi-"
      },
      "source": [
        "# 1.2.3 Eigenvalues and Eigenvectors\n",
        "\n",
        "**Eigenvalue**: Let $A \\epsilon R^{dxd}$ be a square matrix. Then $\\lambda \\epsilon R$ is an eigenvalue of A if there exists a nonzero vector $x \\neq 0$ such that $Ax = \\lambda x$\n",
        "**Eigenvector**: The vector x in the previous equation is referred to as the eigenvector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_GF36v8h5ke",
        "outputId": "239787b5-252e-479b-f1f2-dd373ac2e3a9"
      },
      "source": [
        "a = np.array([[0, 1], [-2, -3]])\n",
        "val, vect = np.linalg.eig(a)\n",
        "print(\"eigenvalues: \", val)\n",
        "print(\"eigenvectors: \", vect)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eigenvalue:  [-1. -2.]\n",
            "eigenvector:  [[ 0.70710678 -0.4472136 ]\n",
            " [-0.70710678  0.89442719]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpbEa-b9ih2f"
      },
      "source": [
        "The above code solves for the eigenvalues and eigenvectors of matrix $a$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ_P5Jf8iwRf",
        "outputId": "b5196f3c-5d12-4ef4-90fa-096af058a44a"
      },
      "source": [
        "a = np.array([[0, -1], [1, 0]])\n",
        "val, vect = np.linalg.eig(a)\n",
        "print(\"eigenvalues: \", val)\n",
        "print(\"eigenvectors: \", vect)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eigenvalue:  [0.+1.j 0.-1.j]\n",
            "eigenvector:  [[0.70710678+0.j         0.70710678-0.j        ]\n",
            " [0.        -0.70710678j 0.        +0.70710678j]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYL14qDsi_Lh"
      },
      "source": [
        "Looking at the code above, the matrix $\\begin{pmatrix}0 & -1\\\\1 & 0\\end{pmatrix}$ has no real solution when solving for eigenvalues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThFklBAWwESz",
        "outputId": "d62b9e62-f60b-43b1-8274-6180cc3eacd4"
      },
      "source": [
        "a = np.array([[5, 2], [2, 5]])\n",
        "val, vect = np.linalg.eig(a)\n",
        "print(\"eigenvalues: \", val)\n",
        "print(\"eigenvectors: \", vect)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eigenvalue:  [7. 3.]\n",
            "eigenvector:  [[ 0.70710678 -0.70710678]\n",
            " [ 0.70710678  0.70710678]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7C9LH2dwSPM"
      },
      "source": [
        "As shown in the code above, if the matrix $a$ is symmetric, then any two eigenvectors from different eigenspaces are orthogonal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbdKfTD6NGj"
      },
      "source": [
        "**Spectral Decomposition**: the spectral decomposition of A is $\\lambda_1v_1v_1^T + \\lambda_2v_2v_2^T + ... + \\lambda_nv_nv_n^T$. Each $v_iv_i^T$ is an n x n matrix of rank 1 and is a projection matrix in the sense that for each $x$ in $R^n$, the vector $v_jv_j^Tx$ is the orthogonal projection of $x$ onto the subspace spanned by $v_j$.\n",
        "\n",
        "**Constrained Optimization**: Let $A$ be a n x n symmetrix matrix with an orthogonal diagonalization of $A = PDP^{-1}$.The columns of $P$ are orthonormal eigenvectors $v_1,...,v_n$ of $A$. Assume the diagonal of D is arranged so that $\\lambda_1 \\leq \\lambda_2 \\leq...\\leq \\lambda_n$. Then $min_{x \\neq 0}\\frac{x^TAx}{x^Tx} = \\lambda_1$ is achieved when $x = v_1$ and $max_{x \\neq 0}\\frac{x^TAx}{x^Tx} = \\lambda_n$ is achieved when $x = v_n$."
      ]
    }
  ]
}