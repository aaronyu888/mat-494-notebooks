{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW 1.3",
      "provenance": [],
      "authorship_tag": "ABX9TyP1n5ViTotiCxiNnfu6bo30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronyu888/mat-494-notebooks/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te1qp7LWvM8V"
      },
      "source": [
        "# Chapter 1.3 Linear Regression\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj0YbBesvf4A"
      },
      "source": [
        "# 1.3.1 QR Decomposition\n",
        "QR factorization takes the general form $A = QR$ where $Q$ is the product of the Gram-Schmidt process, and $R$ is an upper triangular matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBZofZV312JS"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHrfDPe7DizX",
        "outputId": "efdf1950-7a3d-4ed8-9667-e17ffd5f3bfe"
      },
      "source": [
        "A = np.random.randint(10, size = (3, 3))\n",
        "q, r = np.linalg.qr(A)\n",
        "print('A: \\n', A, '\\n')\n",
        "print('Q: \\n', q, '\\n')\n",
        "print('R: \\n', r, '\\n')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: \n",
            " [[4 4 2]\n",
            " [1 6 4]\n",
            " [3 2 7]] \n",
            "\n",
            "Q: \n",
            " [[-0.78446454  0.06052275 -0.6172134 ]\n",
            " [-0.19611614 -0.96836405  0.15430335]\n",
            " [-0.58834841  0.24209101  0.77151675]] \n",
            "\n",
            "R: \n",
            " [[-5.09901951 -5.49125178 -6.47183246]\n",
            " [ 0.         -5.08391127 -2.05777361]\n",
            " [ 0.          0.          4.78340385]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6_ROJpOEtVo",
        "outputId": "8f439f3c-4bae-42a5-e5bd-5bd696e0f7bf"
      },
      "source": [
        "p = (np.matmul(q, r))\n",
        "print(p, '\\n')\n",
        "print(A)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4. 4. 2.]\n",
            " [1. 6. 4.]\n",
            " [3. 2. 7.]] \n",
            "\n",
            "[[4 4 2]\n",
            " [1 6 4]\n",
            " [3 2 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsEl1R6VGxPt"
      },
      "source": [
        "As you can see from the above code, $Q$ dotted with $R$ gives us back $A$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzwrMTu2G-2m"
      },
      "source": [
        "# 1.3.2 Least-squares Problems\n",
        "We are trying to solve for the system $Ax = b$ where $A$ is an $n$ x $m$ matrix and $n > m$. If $n = m$, then we could just find the matrix inverse.\n",
        "Instead, we find an $Ax$ such that we minimize $\\|Ax-b\\|$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ofhHJ6dSImK",
        "outputId": "47d35b39-bdbc-4b42-9e53-0598ff173d72"
      },
      "source": [
        "b = np.random.randint(10, size = (3, 1))\n",
        "x = np.matmul(np.matmul(np.linalg.inv(r),np.transpose(q)), b)\n",
        "Ax = np.matmul(A, x)\n",
        "print('solution vector: \\n', x, '\\n')\n",
        "print('b: \\n', b, '\\n')\n",
        "print('Ax: \\n', Ax, '\\n')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "solution vector: \n",
            " [[ 0.67741935]\n",
            " [-0.37096774]\n",
            " [ 0.38709677]] \n",
            "\n",
            "b: \n",
            " [[2]\n",
            " [0]\n",
            " [4]] \n",
            "\n",
            "Ax: \n",
            " [[2.00000000e+00]\n",
            " [6.66133815e-16]\n",
            " [4.00000000e+00]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXWJovR4WRyd"
      },
      "source": [
        "As you can see from the above code, we generate a random $b$ vector and use the random $A, Q, R$ values from the previous QR decomposition example. $Ax$ should give a close approximation to $b$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAkUfaY2XQKs"
      },
      "source": [
        "# 1.3.3 Linear Regression\n",
        "Linear regression seeks to find an affine function to fit a data set as closely as possible. This is a minimization problem and when looked at in matrix form, is the exact same as the least-squares problem. "
      ]
    }
  ]
}