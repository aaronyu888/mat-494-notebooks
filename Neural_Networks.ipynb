{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsyvN3h0L6Hk5eytNNEbWR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronyu888/mat-494-notebooks/blob/main/Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQOUF-z7O2Ji"
      },
      "source": [
        "# Neural Networks\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njCOrB0xHHDe"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOhYXus6O41c"
      },
      "source": [
        "class Layer:\n",
        "  def __init__(self):\n",
        "    self.input = None\n",
        "    self.output = None\n",
        "\n",
        "  def forward_propagation(self, input):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjnd9NG7Ppf0"
      },
      "source": [
        "# Fully connected layer\n",
        "class FCLayer(Layer):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    self.weights = np.random.rand(input_size, output_size) - 0.5\n",
        "    self.bias = np.random.rand(1, output_size) - 0.5\n",
        "  \n",
        "  def forward_propagation(self, input_data):\n",
        "    self.input = input_data\n",
        "    self.output = np.dot(self.input, self.weights) + self.bias\n",
        "    return self.output\n",
        "  \n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "    input_error = np.dot(output_error, self.weights.T)\n",
        "    weights_error = np.dot(self.input.T, output_error)\n",
        "    \n",
        "    # update params\n",
        "    self.weights -= learning_rate * weights_error\n",
        "    self.bias -= learning_rate * output_error\n",
        "    return input_error"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqU-q3tcPrf-"
      },
      "source": [
        "class ActivationLayer(Layer):\n",
        "  def __init__(self, activation, activation_prime):\n",
        "    self.activation = activation\n",
        "    self.activation_prime = activation_prime\n",
        "\n",
        "  def forward_propagation(self, input_data):\n",
        "    self.input = input_data\n",
        "    self.output = self.activation(self.input)\n",
        "    return self.output\n",
        "\n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "    return self.activation_prime(self.input) * output_error"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AbpggbKJOej"
      },
      "source": [
        "# activation function and derivative\n",
        "def sigmoid(input):\n",
        "  return 1 / (1 + np.exp(-input))\n",
        "\n",
        "def sigmoid_prime(input):\n",
        "  return np.exp(-input) / (1 + np.exp(-input)**2)\n",
        "\n",
        "# cost function and derivative of cost function\n",
        "def mse(y_true, y_pred):\n",
        "  return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "  return 2 * (y_pred - y_true) / y_true.size"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mrIZ3mCJp_6"
      },
      "source": [
        "class Network:\n",
        "  def __init__(self):\n",
        "    self.layers = []\n",
        "    self.loss = None\n",
        "    self.loss_prime = None\n",
        "\n",
        "  def add(self, layer):\n",
        "    self.layers.append(layer)\n",
        "  \n",
        "  def use(self, loss, loss_prime):\n",
        "    self.loss = loss\n",
        "    self.loss_prime = loss_prime\n",
        "\n",
        "  def predict(self, input_data):\n",
        "    samples = len(input_data)\n",
        "    result = []\n",
        "\n",
        "    for i in range(samples):\n",
        "      output = input_data[i]\n",
        "      \n",
        "      for layer in self.layers:\n",
        "        output = layer.forward_propagation(output)\n",
        "      \n",
        "      result.append(output)\n",
        "    \n",
        "    return output\n",
        "  \n",
        "  def fit(self, x_train, y_train, epochs, learning_rate):\n",
        "    # sample dimension first\n",
        "    samples = len(x_train)\n",
        "\n",
        "    # training loop\n",
        "    for i in range(epochs):\n",
        "      err = 0\n",
        "      for j in range(samples):\n",
        "        # forward propagation\n",
        "        output = x_train[j]\n",
        "        for layer in self.layers:\n",
        "          output = layer.forward_propagation(output)\n",
        "\n",
        "        # compute loss (for display purpose only)\n",
        "        err += self.loss(y_train[j], output)\n",
        "\n",
        "        # backward propagation\n",
        "        error = self.loss_prime(y_train[j], output)\n",
        "        for layer in reversed(self.layers):\n",
        "            error = layer.backward_propagation(error, learning_rate)\n",
        "\n",
        "      # calculate average error on all samples\n",
        "      err /= samples\n",
        "      print('epoch %d/%d   error=%f' % (i+1, epochs, err))\n",
        "      \n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLvG01BZLjSI"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eZG5p5zMzlA",
        "outputId": "2536e64e-0141-4516-9caa-1cf1a8a04433"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 1, 28 * 28)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, 28 * 28)\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "net = Network()\n",
        "net.add(FCLayer(28*28, 100))\n",
        "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "net.add(FCLayer(100, 50))\n",
        "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "net.add(FCLayer(50, 10))\n",
        "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "\n",
        "net.use(mse, mse_prime)\n",
        "net.fit(x_train[0:1000], y_train[0:1000], epochs=35, learning_rate=0.1)\n",
        "\n",
        "out = net.predict(x_test[0:3])\n",
        "print(\"\\n\")\n",
        "print(\"predicted values : \")\n",
        "print(out, end=\"\\n\")\n",
        "print(\"true values : \")\n",
        "print(y_test[0:3])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/35   error=0.091170\n",
            "epoch 2/35   error=0.076424\n",
            "epoch 3/35   error=0.063071\n",
            "epoch 4/35   error=0.052722\n",
            "epoch 5/35   error=0.044695\n",
            "epoch 6/35   error=0.038566\n",
            "epoch 7/35   error=0.033817\n",
            "epoch 8/35   error=0.029921\n",
            "epoch 9/35   error=0.026651\n",
            "epoch 10/35   error=0.023925\n",
            "epoch 11/35   error=0.021648\n",
            "epoch 12/35   error=0.019713\n",
            "epoch 13/35   error=0.018051\n",
            "epoch 14/35   error=0.016611\n",
            "epoch 15/35   error=0.015348\n",
            "epoch 16/35   error=0.014224\n",
            "epoch 17/35   error=0.013212\n",
            "epoch 18/35   error=0.012293\n",
            "epoch 19/35   error=0.011457\n",
            "epoch 20/35   error=0.010697\n",
            "epoch 21/35   error=0.010005\n",
            "epoch 22/35   error=0.009376\n",
            "epoch 23/35   error=0.008804\n",
            "epoch 24/35   error=0.008284\n",
            "epoch 25/35   error=0.007813\n",
            "epoch 26/35   error=0.007385\n",
            "epoch 27/35   error=0.006995\n",
            "epoch 28/35   error=0.006640\n",
            "epoch 29/35   error=0.006317\n",
            "epoch 30/35   error=0.006023\n",
            "epoch 31/35   error=0.005753\n",
            "epoch 32/35   error=0.005505\n",
            "epoch 33/35   error=0.005276\n",
            "epoch 34/35   error=0.005064\n",
            "epoch 35/35   error=0.004867\n",
            "\n",
            "\n",
            "predicted values : \n",
            "[[1.59395907e-04 9.34398831e-01 2.13248229e-02 1.10980713e-02\n",
            "  6.29857991e-03 5.03956298e-03 1.11712044e-02 4.34073079e-02\n",
            "  6.45382821e-03 7.53695540e-03]]\n",
            "true values : \n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    }
  ]
}